{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfdc1caa",
   "metadata": {},
   "source": [
    "## CS/INFO 5304 Assignment 2: Recommender Systems\n",
    "\n",
    "#### Credit: 35 points + possible bonus (10 points)\n",
    "#### Due date: May 2nd, 11:59PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67251a",
   "metadata": {},
   "source": [
    "### Part D: bonus [10 points]\n",
    "\n",
    "Your goal is to build a good recommendation system for Yelp with an ensemble of predictors. You can use any individual predictor and any method to combine them (it could be linear weighted combination or vote)\n",
    "\n",
    "- Test set: \n",
    "    - 5 new users x the same 1000 businesses. Their records of the 100 first businesses are also erased.\n",
    "    \n",
    "- Submission: \n",
    "    - the prediction of the erased records which are 1s and 0s.\n",
    "    - Submission format: sample_bonus_submission.csv, (5 rows, 100 columns, separator = comma, integers) Please make sure your raw text exactly matches the sample format. Otherwise you might have 0 points since we run auto grading.\n",
    "    \n",
    "- Evaluation metrics: \n",
    "    - Since the test set is sparse, i.e. most entries are 0s.  We use F1 score as our evaluation metric.\n",
    "    - You can split a validation set out of the training set (for example, user 5-9 ) if you want to test your model. \n",
    "    \n",
    "- Code and write-up:\n",
    "    - Write your code for the test set in a separate jupyter notebook. At the top of the notebook, add brief write-ups to explain each predictor you used and how you combined them.\n",
    "    - Your bonus points = max(10*min( yourF1 - 0.120.5 - 0.12, 1), 0)\n",
    "        - This means that you will get some points as long as you attempt! For reference, a random guess(all as 1s) is 0.12. And 0.6 is pretty accurate.\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1dbf0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "\n",
    "# Load the datasets\n",
    "business_df = pd.read_csv('data/business.csv', header = None, names = [\"Business\"])\n",
    "user_business_df = pd.read_csv('data/user-business.csv', header = None)\n",
    "user_business_test_df = pd.read_csv('data/user-business_test.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c60395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "def normalize_arr(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "class my_recom_system:\n",
    "    def __init__(self, erased_vals = 100, train_sample = 10, epochs = 10, \n",
    "                 weight_step_limit = 0.05, bias = 0.3):\n",
    "        self.erased_vals = erased_vals\n",
    "        self.weights = np.array([0.5, 0.5])\n",
    "        self.bias = bias\n",
    "        self.train_sample = train_sample\n",
    "        self.epochs = epochs\n",
    "        self.weight_step_limit = weight_step_limit\n",
    "\n",
    "    def train(self):\n",
    "        best_weights = self.weights.copy()\n",
    "        prev_increm_idx = 0\n",
    "        bias_increm_sign = 1\n",
    "        best_f1_score = 0.0\n",
    "        best_bias = self.bias\n",
    "        \n",
    "        random_user_train_sample = random.sample(range(len(user_business_df)), self.train_sample)\n",
    "        for e in range(1, self.epochs + 1):\n",
    "            curr_f1_score = 0.0\n",
    "            \n",
    "            for i in random_user_train_sample:\n",
    "                user_row = user_business_df.iloc[i, :].copy()\n",
    "                user_row_targets = user_row[:self.erased_vals].copy()\n",
    "                user_row[:self.erased_vals] = 0\n",
    "\n",
    "                predictions = self.predict(user_business_df, user_row, i)\n",
    "                curr_f1_score += f1_score(user_row_targets, predictions, zero_division = 1) / \\\n",
    "                                 self.train_sample\n",
    "            \n",
    "            \n",
    "            print(\"epoch: \", e, \"\\t F1 Score: \", curr_f1_score, \n",
    "                  \"\\t Bias-Weights: \", self.bias, \" - \", self.weights)  \n",
    "            \n",
    "            if curr_f1_score < best_f1_score:\n",
    "                self.weights = best_weights.copy()\n",
    "                prev_increm_idx = (prev_increm_idx + 1) % 2\n",
    "                self.bias = best_bias\n",
    "                bias_increm_sign *= -1\n",
    "            else :\n",
    "                best_weights = self.weights.copy()\n",
    "                best_f1_score = curr_f1_score\n",
    "                best_bias = self.bias                \n",
    "            \n",
    "            weight_rand_increment = random.uniform(0, self.weight_step_limit)\n",
    "            self.bias += bias_increm_sign * random.uniform(0, 0.05)\n",
    "            self.weights -= weight_rand_increment\n",
    "            self.weights[prev_increm_idx] += 2 * weight_rand_increment\n",
    "    \n",
    "        # Chose best weights and bias.\n",
    "#         self.bias = best_bias\n",
    "#         self.weights = best_weights\n",
    "    \n",
    "    def predict(self, user_df, user_row, i):\n",
    "     \n",
    "        # user system\n",
    "        user_simil_matrix = cosine_similarity(user_df.iloc[:, self.erased_vals:], \n",
    "                                      np.array(user_row[self.erased_vals:]).reshape(1, -1))\n",
    "        user_recomm_matrix = normalize_arr(np.dot(user_simil_matrix.T, user_df)\n",
    "                                          ).flatten()[:self.erased_vals]\n",
    "        \n",
    "        # item system    \n",
    "        item_simil_matrix = cosine_similarity(user_df.drop(labels = [i], axis = 0).T)\n",
    "        item_recomm_matrix = normalize_arr(np.dot(user_row, item_simil_matrix)\n",
    "                                          )[:self.erased_vals]\n",
    "\n",
    "        mixed_score = self.bias + user_recomm_matrix * self.weights[0] + \\\n",
    "                      item_recomm_matrix * self.weights[1]\n",
    "        predictions = (mixed_score > 0.5).astype(int)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    def test(self, user_df):\n",
    "        all_preds = np.zeros_like(user_df.iloc[:, :self.erased_vals])\n",
    "        for i in range(len(user_df)):\n",
    "            user_row = user_df.iloc[i, :].copy()\n",
    "            predictions = self.predict(user_business_df, user_row, i)\n",
    "            all_preds[i, :] = predictions\n",
    "        \n",
    "        pred_df = pd.DataFrame(all_preds)\n",
    "        return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a3b9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 \t F1 Score:  0.33631287601287607 \t Bias-Weights:  0.3  -  [0.5 0.5]\n",
      "epoch:  2 \t F1 Score:  0.25549249378072914 \t Bias-Weights:  0.3388049400259937  -  [0.53378123 0.46621877]\n",
      "epoch:  3 \t F1 Score:  0.414458585858586 \t Bias-Weights:  0.25039423138531414  -  [0.48098335 0.51901665]\n",
      "epoch:  4 \t F1 Score:  0.4744366522366524 \t Bias-Weights:  0.20861170422933922  -  [0.43306314 0.56693686]\n",
      "epoch:  5 \t F1 Score:  0.4937033189033191 \t Bias-Weights:  0.20078403246889065  -  [0.40450134 0.59549866]\n",
      "epoch:  6 \t F1 Score:  0.5289532467532473 \t Bias-Weights:  0.17089912619931685  -  [0.38134285 0.61865715]\n",
      "epoch:  7 \t F1 Score:  0.5549437229437234 \t Bias-Weights:  0.145271374958865  -  [0.35648908 0.64351092]\n",
      "epoch:  8 \t F1 Score:  0.5931777777777782 \t Bias-Weights:  0.11231274897808666  -  [0.31981355 0.68018645]\n",
      "epoch:  9 \t F1 Score:  0.5976952380952385 \t Bias-Weights:  0.10245075141367904  -  [0.31683343 0.68316657]\n",
      "epoch:  10 \t F1 Score:  0.6032571428571433 \t Bias-Weights:  0.06358930261093203  -  [0.30865834 0.69134166]\n",
      "epoch:  11 \t F1 Score:  0.5888000000000004 \t Bias-Weights:  0.014600552601647929  -  [0.28803415 0.71196585]\n",
      "epoch:  12 \t F1 Score:  0.5973333333333338 \t Bias-Weights:  0.10442177340484361  -  [0.35623131 0.64376869]\n",
      "epoch:  13 \t F1 Score:  0.5873333333333337 \t Bias-Weights:  0.014133634708172853  -  [0.30708389 0.69291611]\n",
      "epoch:  14 \t F1 Score:  0.5974666666666671 \t Bias-Weights:  0.07443180133644649  -  [0.31898832 0.68101168]\n",
      "epoch:  15 \t F1 Score:  0.6029904761904766 \t Bias-Weights:  0.05077142698161924  -  [0.29442965 0.70557035]\n",
      "epoch:  16 \t F1 Score:  0.5904000000000005 \t Bias-Weights:  0.08453396435935642  -  [0.31427829 0.68572171]\n",
      "epoch:  17 \t F1 Score:  0.6006285714285718 \t Bias-Weights:  0.041111618770367314  -  [0.28491861 0.71508139]\n",
      "epoch:  18 \t F1 Score:  0.6024000000000005 \t Bias-Weights:  0.08776131186286636  -  [0.32458277 0.67541723]\n",
      "epoch:  19 \t F1 Score:  0.6028952380952385 \t Bias-Weights:  0.04798496012161901  -  [0.29678027 0.70321973]\n",
      "epoch:  20 \t F1 Score:  0.5984000000000005 \t Bias-Weights:  0.08854727010241309  -  [0.32872796 0.67127204]\n",
      "epoch:  21 \t F1 Score:  0.5886285714285718 \t Bias-Weights:  0.027497889168378996  -  [0.26114623 0.73885377]\n",
      "epoch:  22 \t F1 Score:  0.5901333333333338 \t Bias-Weights:  0.07964346387800719  -  [0.3566824 0.6433176]\n",
      "epoch:  23 \t F1 Score:  0.6021904761904766 \t Bias-Weights:  0.06343443803560035  -  [0.29594416 0.70405584]\n",
      "epoch:  24 \t F1 Score:  0.60232380952381 \t Bias-Weights:  0.07317879669981303  -  [0.34294102 0.65705898]\n",
      "epoch:  25 \t F1 Score:  0.5925333333333338 \t Bias-Weights:  0.022007202239848984  -  [0.30382092 0.69617908]\n"
     ]
    }
   ],
   "source": [
    "recom_sys = my_recom_system(train_sample = 250, epochs = 25)\n",
    "\n",
    "recom_sys.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79276d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  90  91  92  93  94  95  96  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "1   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2   0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3   0   0   0   0   0   0   0   0   1   0  ...   0   0   0   0   0   0   0   \n",
       "4   0   0   0   0   0   0   0   0   0   0  ...   1   1   0   0   0   0   0   \n",
       "\n",
       "   97  98  99  \n",
       "0   0   0   0  \n",
       "1   1   0   0  \n",
       "2   0   0   1  \n",
       "3   0   0   0  \n",
       "4   0   0   0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = recom_sys.test(user_business_test_df)\n",
    "\n",
    "display(test_predictions)\n",
    "test_predictions.to_csv(\"bonus_submission.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae352ac5",
   "metadata": {},
   "source": [
    "### Turn in:\n",
    "#### A2\n",
    "    a) A Jupyter notebook a2.jpynb with the code and answers (if you work in a study group, write their names at the top to avoid any trouble in the plagiarism check. And we encourage you to write your code independently.)\n",
    "    b) A a2.py exported from your .jpynb\n",
    "\n",
    "#### A2-bonus\n",
    "    c) bonus_submission.csv\n",
    "    d) bonus.ipynb\n",
    "    e) A bonus.py exported from your .jpynb (last time, some students submit an unexpected messy file with the raw content of Jupyter. Please make sure it is the exported one with codes only.)\n",
    "\n",
    "__Please double check that you have all the required files submitted!__ Last time we received many regrading requests about this. In this and the following assignments, we will need to apply at least 20% penalty."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
