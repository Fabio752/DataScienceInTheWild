{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfdc1caa",
   "metadata": {},
   "source": [
    "## CS/INFO 5304 Assignment 2: Recommender Systems\n",
    "\n",
    "#### Credit: 35 points + possible bonus (10 points)\n",
    "#### Due date: May 2nd, 11:59PM\n",
    " \n",
    "The goal of the assignment is to get familiar with different types of recommender systems. Specifically, we are going to build a system that can recommend Yelp businesses to users.\n",
    " \n",
    " \n",
    "### Dataset\n",
    "The dataset that we will be using contains information about Yelp businesses. More precisely, for 14397 active users and 1000 popular businesses on Yelp, we know if a given user visited&rated a given business, for example, a restaurant.\n",
    " \n",
    " \n",
    "The folder contains:\n",
    " \n",
    "- __user-business.csv__ - This is the ratings matrix R, where each row corresponds to a user and each column corresponds to a business. Rij = 1 if the user has visited&rated that business. Otherwise  Rij = 0. (To simplify the question, we ignore the exact ratings.) The columns are separated by a space.\n",
    " \n",
    "- __business.csv__ - This is a file containing the names of the businesses, in the same order as the columns of R.\n",
    " \n",
    "The dataset can be found here: Google drive.\n",
    "  \n",
    "\n",
    "### Overview\n",
    " \n",
    "In this assignment we are going to implement three types of recommender systems namely\n",
    " \n",
    "- __User__ - User recommender system\n",
    "- __Item__ – Item recommender system\n",
    "- Latent factor model recommender system\n",
    " \n",
    " \n",
    "We are then going to compare the results of these systems for the 4th user(index starting from 1) of the dataset. Let’s call him Alex. In order to do so, we have erased the first 100 entries of Alex’s row in the matrix, and replaced them by 0s. This means that we don’t know which of the first 100 businesses Alex has visited. Based on Alex’s behavior on the other businesses, you need to give Alex recommendations on the first 100 businesses. We will then see if our recommendations match what Alex had in fact visited.\n",
    "\n",
    "To verify your output using the following recommenders, the 1s in the erased first entries are:\n",
    "- Piece of Cake\n",
    "- Papi's Cuban & Caribbean Grill\n",
    "- Loca Luna\n",
    "- Farm Burger\n",
    "- Little Rey\n",
    "- Seven Lamps\n",
    "- Vatica Indian Cuisine\n",
    "- Shake Shack\n",
    "- Truva Turkish Kitchen\n",
    "- Yoi Yoi Japanese Steakhouse & Sushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5de234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top_k(business_df, recom_mat, k = 5):\n",
    "    df = pd.DataFrame(index = range(1, 6))\n",
    "\n",
    "    top_k_idxs = recom_mat.argsort()[-k:][::-1]\n",
    "\n",
    "    df[\"Business\"] = np.array(business_df.iloc[top_k_idxs, 0])\n",
    "    df[\"Similarity Score\"] = np.array(recom_mat[top_k_idxs])\n",
    "\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bc90b1",
   "metadata": {},
   "source": [
    "### Part A: user – user recommender system [10 points]\n",
    " \n",
    "In a user-user recommender system, you need to find users who have visited and rated similar businesses. Then among these users, you can recommend the top visited items.\n",
    "\n",
    "for all businesses b, compute\n",
    "\n",
    "$$ r_{Alex,b} = \\sum_{x∈users} cos-sim(x, Alex)·R_{x,b} $$\n",
    "\n",
    "where $cos-sim(x,Alex)$ is the cosine similarity of other users with Alex (excluding entries of the first 100 businesses), and $R$ is the ratings matrix. \n",
    "\n",
    "In the above equation you are first finding the similarity between users and then multiplying it with their product rating for each item. So the businesses that have higher $r_{Alex,b}$ will be the businesses that are popular among the users similar to Alex.\n",
    " \n",
    "Let $S$ denote the set of the first 100 businesses (the first 100 columns of the matrix). From all the businesses in $S$, which are the five that have the highest similarity scores ($r_{Alex,b}$) for Alex? What are their similarity scores? In case of ties between two businesses, choose the one with a smaller index. Do not write the index of the businesses, write their names using the file __business.csv__.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc64fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the datasets\n",
    "business_df = pd.read_csv('data/business.csv', header = None, names = [\"Business\"])\n",
    "user_business_df = pd.read_csv('data/user-business.csv', header = None)\n",
    "\n",
    "alex_idx, alex_erased_vals = 3, 100\n",
    "\n",
    "user_business_df.iloc[alex_idx, :alex_erased_vals] = 0\n",
    "alex_row = user_business_df.iloc[alex_idx, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ec7796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Papi's Cuban &amp; Caribbean Grill</td>\n",
       "      <td>43.039527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seven Lamps</td>\n",
       "      <td>33.598188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Loca Luna</td>\n",
       "      <td>33.263225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Farm Burger</td>\n",
       "      <td>32.782940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Piece of Cake</td>\n",
       "      <td>12.626244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Business  Similarity Score\n",
       "1  Papi's Cuban & Caribbean Grill         43.039527\n",
       "2                     Seven Lamps         33.598188\n",
       "3                       Loca Luna         33.263225\n",
       "4                     Farm Burger         32.782940\n",
       "5                   Piece of Cake         12.626244"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_simil_matrix = cosine_similarity(user_business_df.iloc[:, alex_erased_vals:], \n",
    "                                      np.array(alex_row[alex_erased_vals:]).reshape(1, -1))\n",
    "user_recomm_matrix = np.dot(user_simil_matrix.T, user_business_df).flatten()\n",
    "\n",
    "display_top_k(business_df, user_recomm_matrix[:alex_erased_vals])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a111a7f6",
   "metadata": {},
   "source": [
    "### Part B: item – item recommender system [10 points]\n",
    " \n",
    "In an item-item recommender system, you need to find items that have similar ratings and recommend it to Alex. For all business b, compute\n",
    " \n",
    " $$r_{Alex,b} = \\sum_{x ∈ business} cos-sim(x, b)·R_{Alex,x}$$ \n",
    " \n",
    "where $R$ is the ratings matrix and $cos-sim(x,b)$ is the cosine-similarity of each pair of businesses(excluding entries of Alex).  Here you are finding similar items and then multiplying it with Alex’s ratings for items. So the businesses that are similar to the businesses already visited by Alex will have the higher rating $r$\n",
    " \n",
    "From all the businesses in $S$ (first 100 businesses), which are the five that have the highest similarity scores for Alex?  In case of ties between two businesses, choose the one with a smaller index. Again, hand in the names of the businesses and their similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3715dc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Papi's Cuban &amp; Caribbean Grill</td>\n",
       "      <td>6.810937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Farm Burger</td>\n",
       "      <td>6.558815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seven Lamps</td>\n",
       "      <td>6.440367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Loca Luna</td>\n",
       "      <td>5.852681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Piece of Cake</td>\n",
       "      <td>3.730178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Business  Similarity Score\n",
       "1  Papi's Cuban & Caribbean Grill          6.810937\n",
       "2                     Farm Burger          6.558815\n",
       "3                     Seven Lamps          6.440367\n",
       "4                       Loca Luna          5.852681\n",
       "5                   Piece of Cake          3.730178"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "item_simil_matrix = cosine_similarity(user_business_df.drop(labels = [alex_idx], axis = 0).T)\n",
    "item_recomm_matrix = np.dot(alex_row, item_simil_matrix)\n",
    "\n",
    "display_top_k(business_df, item_recomm_matrix[:alex_erased_vals])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dcd805",
   "metadata": {},
   "source": [
    "### Part C: Latent hidden model recommender system [15 points]\n",
    " \n",
    "Latent model recommender system is the most popular type of recommender system in the market today. Here we perform a matrix factorization of the ratings matrix $R$ into two matrices $U$ and $V$ where $U$ is considered as the user features matrix and $V$ is the movie features matrix. Note that the features are ‘hidden’ and need not be understandable to users. Hence the name latent hidden model. (refer slides for more information)\n",
    " \n",
    "The latent model can be implemented by performing a singular value decomposition (SVD) that factors the matrix into three matrices\n",
    " \n",
    "$$ R = U ΣV^T $$\n",
    " \n",
    "where $R$ is user ratings matrix, $U$ is the user “features” matrix, $Σ$ is the diagonal matrix of singular values (essentially weights), and $V^T$ is the movie “features” matrix. $U$ and $V^T$ are orthogonal, and represent different things. $U$ represents how much users “like” each feature and VT represents how relevant each feature is to each business.\n",
    "\n",
    "To get the lower rank approximation, we take these matrices and keep only the top $k$ features ($k$ factors), which we think of as the $k$ most important underlying taste and preference vectors.\n",
    " \n",
    "With $k$ set to 10, perform SVD to identify the $U$ and $V$ matrices. You can then multiply the matrices to estimate the following\n",
    " \n",
    "$$R^* = U Σ V^T$$\n",
    "\n",
    "From the $R^*$ matrix, select the top 5 businesses for Alex in $S$ (first 100 businesses). In case of ties between two businesses, choose the one with a smaller index. Again, hand in the names of the businesses and their similarity score.\n",
    " \n",
    "Hint: You can use SVD in scipy, numpy, or surprise package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bedd652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Papi's Cuban &amp; Caribbean Grill</td>\n",
       "      <td>1.190506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Loca Luna</td>\n",
       "      <td>0.876255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Farm Burger</td>\n",
       "      <td>0.857826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seven Lamps</td>\n",
       "      <td>0.817947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Piece of Cake</td>\n",
       "      <td>0.299354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Business  Similarity Score\n",
       "1  Papi's Cuban & Caribbean Grill          1.190506\n",
       "2                       Loca Luna          0.876255\n",
       "3                     Farm Burger          0.857826\n",
       "4                     Seven Lamps          0.817947\n",
       "5                   Piece of Cake          0.299354"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.linalg import svd\n",
    "\n",
    "U, Sigma, V_t = svd(user_business_df)\n",
    "\n",
    "f = 10\n",
    "U_k, Sigma_k, V_t_k = U[:, :f], np.diag(Sigma[:f]), V_t[:f, :]\n",
    "R_star = np.dot(U_k, np.dot(Sigma_k, V_t_k))\n",
    "\n",
    "alex_row = R_star[alex_idx, :alex_erased_vals]\n",
    "\n",
    "display_top_k(business_df, alex_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67251a",
   "metadata": {},
   "source": [
    "### Part D: bonus [10 points]\n",
    "\n",
    "Your goal is to build a good recommendation system for Yelp with an ensemble of predictors. You can use any individual predictor and any method to combine them (it could be linear weighted combination or vote)\n",
    "\n",
    "- Test set: \n",
    "    - 5 new users x the same 1000 businesses. Their records of the 100 first businesses are also erased.\n",
    "    \n",
    "- Submission: \n",
    "    - the prediction of the erased records which are 1s and 0s.\n",
    "    - Submission format: sample_bonus_submission.csv, (5 rows, 100 columns, separator = comma, integers) Please make sure your raw text exactly matches the sample format. Otherwise you might have 0 points since we run auto grading.\n",
    "    \n",
    "- Evaluation metrics: \n",
    "    - Since the test set is sparse, i.e. most entries are 0s.  We use F1 score as our evaluation metric.\n",
    "    - You can split a validation set out of the training set (for example, user 5-9 ) if you want to test your model. \n",
    "    \n",
    "- Code and write-up:\n",
    "    - Write your code for the test set in a separate jupyter notebook. At the top of the notebook, add brief write-ups to explain each predictor you used and how you combined them.\n",
    "    - Your bonus points = max(10*min( yourF1 - 0.120.5 - 0.12, 1), 0)\n",
    "        - This means that you will get some points as long as you attempt! For reference, a random guess(all as 1s) is 0.12. And 0.6 is pretty accurate.\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d4f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the datasets\n",
    "business_df = pd.read_csv('data/business.csv', header = None, names = [\"Business\"])\n",
    "user_business_df = pd.read_csv('data/user-business.csv', header = None)\n",
    "user_business_test_df = pd.read_csv('data/user-business_test.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e9b947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "def normalize_arr(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "class my_recom_system:\n",
    "    def __init__(self, erased_vals = 100, train_sample = 10, epochs = 10, \n",
    "                 weight_step_limit = 0.05, bias = 0.3):\n",
    "        self.erased_vals = erased_vals\n",
    "        self.weights = np.array([0.5, 0.5])\n",
    "        self.bias = bias\n",
    "        self.train_sample = train_sample\n",
    "        self.epochs = epochs\n",
    "        self.weight_step_limit = weight_step_limit\n",
    "\n",
    "    def train(self):\n",
    "        best_weights = self.weights.copy()\n",
    "        prev_increm_idx = 0\n",
    "        bias_increm_sign = 1\n",
    "        best_f1_score = 0.0\n",
    "        best_bias = self.bias\n",
    "        \n",
    "        random_user_train_sample = random.sample(range(len(user_business_df)), self.train_sample)\n",
    "        for e in range(1, self.epochs + 1):\n",
    "            curr_f1_score = 0.0\n",
    "            \n",
    "            for i in random_user_train_sample:\n",
    "                user_row = user_business_df.iloc[i, :].copy()\n",
    "                user_row_targets = user_row[:self.erased_vals].copy()\n",
    "                user_row[:self.erased_vals] = 0\n",
    "\n",
    "                predictions = self.predict(user_business_df, user_row, i)\n",
    "                curr_f1_score += f1_score(user_row_targets, predictions, zero_division = 1) / \\\n",
    "                                 self.train_sample\n",
    "            \n",
    "            \n",
    "            print(\"epoch: \", e, \"\\t F1 Score: \", curr_f1_score, \n",
    "                  \"\\t Bias-Weights: \", self.bias, \" - \", self.weights)  \n",
    "            \n",
    "            if curr_f1_score < best_f1_score:\n",
    "                self.weights = best_weights.copy()\n",
    "                prev_increm_idx = (prev_increm_idx + 1) % 2\n",
    "                self.bias = best_bias\n",
    "                bias_increm_sign *= -1\n",
    "            else :\n",
    "                best_weights = self.weights.copy()\n",
    "                best_f1_score = curr_f1_score\n",
    "                best_bias = self.bias                \n",
    "            \n",
    "            weight_rand_increment = random.uniform(0, self.weight_step_limit)\n",
    "            self.bias += bias_increm_sign * random.uniform(0, 0.05)\n",
    "            self.weights -= weight_rand_increment\n",
    "            self.weights[prev_increm_idx] += 2 * weight_rand_increment\n",
    "    \n",
    "        # Chose best weights and bias.\n",
    "#         self.bias = best_bias\n",
    "#         self.weights = best_weights\n",
    "    \n",
    "    def predict(self, user_df, user_row, i):\n",
    "        # user system\n",
    "        user_simil_matrix = cosine_similarity(user_df.iloc[:, self.erased_vals:], \n",
    "                                      np.array(user_row[self.erased_vals:]).reshape(1, -1))\n",
    "        user_recomm_matrix = normalize_arr(np.dot(user_simil_matrix.T, user_df)\n",
    "                                          ).flatten()[:self.erased_vals]\n",
    "        \n",
    "#         user_simil_matrix = cosine_similarity(user_df, np.array(user_row).reshape(1, -1))\n",
    "#         user_recomm_matrix = normalize_arr(np.dot(user_simil_matrix.T, user_df)).flatten()[:self.erased_vals]\n",
    "\n",
    "        # item system\n",
    "    \n",
    "        item_simil_matrix = cosine_similarity(user_df.drop(labels = [i], axis = 0).T)\n",
    "        item_recomm_matrix = normalize_arr(np.dot(user_row, item_simil_matrix)\n",
    "                                          )[:self.erased_vals]\n",
    "\n",
    "#         item_simil_matrix = cosine_similarity(user_df.T)\n",
    "#         item_recomm_matrix = normalize_arr(np.dot(user_row, item_simil_matrix))[:self.erased_vals]\n",
    "        \n",
    "        mixed_score = self.bias + user_recomm_matrix * self.weights[0] + \\\n",
    "                      item_recomm_matrix * self.weights[1]\n",
    "        predictions = (mixed_score > 0.5).astype(int)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    def test(self, user_df):\n",
    "        all_preds = np.zeros_like(user_df.iloc[:, :self.erased_vals])\n",
    "        for i in range(len(user_df)):\n",
    "            user_row = user_df.iloc[i, :].copy()\n",
    "            predictions = self.predict(user_business_df, user_row, i)\n",
    "            all_preds[i, :] = predictions\n",
    "        \n",
    "        pred_df = pd.DataFrame(all_preds)\n",
    "        return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71e30e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 \t F1 Score:  0.24683859999649474 \t Bias-Weights:  0.3  -  [0.5 0.5]\n",
      "epoch:  2 \t F1 Score:  0.21737562437562438 \t Bias-Weights:  0.32749196447578327  -  [0.51987709 0.48012291]\n",
      "epoch:  3 \t F1 Score:  0.28721428571428576 \t Bias-Weights:  0.25009684151025585  -  [0.47688532 0.52311468]\n",
      "epoch:  4 \t F1 Score:  0.3407777777777778 \t Bias-Weights:  0.20539801250401565  -  [0.43550881 0.56449119]\n",
      "epoch:  5 \t F1 Score:  0.3772727272727273 \t Bias-Weights:  0.17630011870866005  -  [0.4309508 0.5690492]\n",
      "epoch:  6 \t F1 Score:  0.4387142857142858 \t Bias-Weights:  0.1582573046458343  -  [0.39150613 0.60849387]\n",
      "epoch:  7 \t F1 Score:  0.437936507936508 \t Bias-Weights:  0.13494863237482072  -  [0.3914683 0.6085317]\n",
      "epoch:  8 \t F1 Score:  0.3407777777777778 \t Bias-Weights:  0.20085027852706341  -  [0.44121234 0.55878766]\n",
      "epoch:  9 \t F1 Score:  0.4314285714285715 \t Bias-Weights:  0.11444545071470597  -  [0.390782 0.609218]\n",
      "epoch:  10 \t F1 Score:  0.35611111111111116 \t Bias-Weights:  0.17876587759990453  -  [0.40685825 0.59314175]\n",
      "epoch:  11 \t F1 Score:  0.41871428571428576 \t Bias-Weights:  0.14749913356754968  -  [0.34163676 0.65836324]\n",
      "epoch:  12 \t F1 Score:  0.3407777777777778 \t Bias-Weights:  0.19824318019039827  -  [0.40450891 0.59549109]\n",
      "epoch:  13 \t F1 Score:  0.4314285714285715 \t Bias-Weights:  0.11047504663969654  -  [0.37849541 0.62150459]\n",
      "epoch:  14 \t F1 Score:  0.3407777777777778 \t Bias-Weights:  0.20169349178760346  -  [0.43741436 0.56258564]\n",
      "epoch:  15 \t F1 Score:  0.443936507936508 \t Bias-Weights:  0.1401602325115374  -  [0.37213299 0.62786701]\n",
      "epoch:  16 \t F1 Score:  0.41142857142857153 \t Bias-Weights:  0.0921914643675771  -  [0.34291527 0.65708473]\n",
      "epoch:  17 \t F1 Score:  0.41871428571428576 \t Bias-Weights:  0.16502560314256412  -  [0.41400776 0.58599224]\n",
      "epoch:  18 \t F1 Score:  0.443936507936508 \t Bias-Weights:  0.12850451347157024  -  [0.34292428 0.65707572]\n",
      "epoch:  19 \t F1 Score:  0.443936507936508 \t Bias-Weights:  0.11046544240842464  -  [0.29735552 0.70264448]\n",
      "epoch:  20 \t F1 Score:  0.4412698412698413 \t Bias-Weights:  0.10538814484642976  -  [0.26169368 0.73830632]\n"
     ]
    }
   ],
   "source": [
    "recom_sys = my_recom_system(train_sample = 50, epochs = 20)\n",
    "recom_sys.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5de3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  90  91  92  93  94  95  96  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "1   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2   0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3   0   0   0   0   0   0   0   0   1   0  ...   0   0   0   0   0   0   0   \n",
       "4   0   0   0   0   0   0   0   0   0   0  ...   1   1   0   0   0   0   0   \n",
       "\n",
       "   97  98  99  \n",
       "0   0   0   0  \n",
       "1   1   0   0  \n",
       "2   0   0   1  \n",
       "3   0   0   0  \n",
       "4   0   0   0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = recom_sys.test(user_business_test_df)\n",
    "test_predictions.to_csv(\"bonus_submission.csv\", header = False, index = False)\n",
    "\n",
    "display(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae352ac5",
   "metadata": {},
   "source": [
    "### Turn in:\n",
    "#### A2\n",
    "    a) A Jupyter notebook a2.jpynb with the code and answers (if you work in a study group, write their names at the top to avoid any trouble in the plagiarism check. And we encourage you to write your code independently.)\n",
    "    b) A a2.py exported from your .jpynb\n",
    "\n",
    "#### A2-bonus\n",
    "    c) bonus_submission.csv\n",
    "    d) bonus.ipynb\n",
    "    e) A bonus.py exported from your .jpynb (last time, some students submit an unexpected messy file with the raw content of Jupyter. Please make sure it is the exported one with codes only.)\n",
    "\n",
    "__Please double check that you have all the required files submitted!__ Last time we received many regrading requests about this. In this and the following assignments, we will need to apply at least 20% penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7cdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
